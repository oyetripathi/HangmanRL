{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random, string\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from network import BaseModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"words_250000_train.txt\", \"r\")\n",
    "all_words = f.read().splitlines()\n",
    "maxlen = max([len(word) for word in all_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(all_words)\n",
    "n = len(all_words)\n",
    "train_split = 0.8\n",
    "train_words = all_words[:int(train_split*n)]\n",
    "test_words = all_words[int(train_split*n):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_masked_words(word_list):\n",
    "  ret = {}\n",
    "  for word in tqdm(word_list):\n",
    "    orig = word\n",
    "    chars = list(set([c for c in word]))\n",
    "    num_dels = random.choice(range(1,len(chars)+1))\n",
    "    del_chars = random.choices(chars, k = num_dels)\n",
    "    for c in del_chars:\n",
    "      word = word.replace(c, '_')\n",
    "    ret[orig] = word\n",
    "  return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/181840 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 181840/181840 [00:00<00:00, 264055.00it/s]\n",
      "100%|██████████| 45460/45460 [00:00<00:00, 257825.17it/s]\n"
     ]
    }
   ],
   "source": [
    "train_masked_words, test_masked_words = get_masked_words(train_words), get_masked_words(test_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = list(train_masked_words.values()), list(train_masked_words.keys())\n",
    "x_test, y_test = list(test_masked_words.values()), list(test_masked_words.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_letters = set(string.ascii_lowercase)\n",
    "letters = list(set_letters)\n",
    "letters.sort()\n",
    "letter_dict = {l : i+1 for i, l in enumerate(letters)}\n",
    "letter_dict['_'] = 27\n",
    "\n",
    "def letter_to_num(c):\n",
    "  return letter_dict[c]\n",
    "\n",
    "def process_input(words):\n",
    "  seq = [list(map(letter_to_num, word)) for word in words]\n",
    "  return pad_sequences(seq, maxlen = maxlen, padding=\"post\", value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = process_input(x_train)\n",
    "x_test = process_input(x_test)\n",
    "y_train = process_input(y_train)\n",
    "y_test = process_input(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(buffer_size=1000).batch(200)\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test)).shuffle(buffer_size=1000).batch(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = BaseModel(vocab_size = 28, maxlen=maxlen, embed_size = 512, num_heads = 64, key_dim = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = tf.keras.layers.Input(shape=(maxlen))\n",
    "attn = base_model(inp)\n",
    "dense1 = tf.keras.layers.Dense(512, activation='relu')(attn)\n",
    "dense2 = tf.keras.layers.Dense(256, activation='relu')(dense1)\n",
    "dense3 = tf.keras.layers.Dense(64, activation='relu')(dense2)\n",
    "out = tf.keras.layers.Dense(28, activation='softmax')(dense3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 29)]              0         \n",
      "                                                                 \n",
      " base_model (BaseModel)      (None, 29, 512)           278400    \n",
      "                                                                 \n",
      " dense (Dense)               (None, 29, 512)           262656    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 29, 256)           131328    \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 29, 64)            16448     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 29, 28)            1820      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 690652 (2.63 MB)\n",
      "Trainable params: 690652 (2.63 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Model(inputs=inp, outputs=out)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = tf.losses.SparseCategoricalCrossentropy()\n",
    "optimizer = tf.optimizers.Adam()\n",
    "model.compile(loss=loss_fn, optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_ds, validation_data=test_ds, epochs = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.save_weights('base_model_weights_64x512.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 10\n",
    "target = random.choices(list(test_masked_words.keys()), k = num_samples)\n",
    "source = [test_masked_words[word] for word in target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = np.argmax(model.predict(process_input(source)), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_letter = {v:k for k,v in letter_dict.items()}\n",
    "inv_letter[0] = '.'\n",
    "\n",
    "def num_to_letter(num):\n",
    "  return inv_letter[num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Predicted Words: \", [''.join(list(map(num_to_letter, seq))).replace('.','') for seq in pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Original Words: \", {k:v for k,v in zip(source, target)})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
